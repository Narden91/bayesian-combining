hydra:
  job_logging:
    root:
      handlers: [console]
      level: INFO
      formatter: simple
    formatters:
      simple:
        format: "[%(asctime)s][%(filename)s][%(levelname)s] - %(message)s"
        datefmt: "%d-%m-%Y %H:%M:%S"
  run:
    dir: .
  output_subdir: null

settings:
  seed: 42
  runs: 1
  verbose: False
  debug: False
  results_analysis: False
  type: DL # ML or DL
  tasks: False
  task_list: ["Task_16", "Task_21"]

paths:
  source: data
  output: output

data:
  #dataset: ['ConvNeXtSmall', 'EfficientNetV2S', 'InceptionResNetV2', 'InceptionV3', 'All', 'InAir', 'OnPaper', 'InAirOnPaper']
  dataset: ['ConvNeXtSmall', 'InAir'] # All, InAir, OnPaper, InAirOnPaper , ConvNeXtSmall, EfficientNetV2S, InceptionResNetV2
  extension: csv
  separator: ","
  target: Label
  id: Id
  id_index: Id_index

scaling:
  type: Robust

model:
  name: DecisionTree # RandomForest, SVC, DecisionTree, XGB

optuna:
  n_trials: 2

experiment:
  train_size: 0.7 # 0.5 for stacking Classification
  test_size: 0.3 # 0.5 for stacking Classification
  test_size_final: 0.2
  val_size: 0.2
  folds: 5
  calibration: True
  calibration_method: isotonic
  calibration_cv: 5
  stacking_method: Bayesian # Bayesian, Classification, MajorityVote, WeightedMajorityVote
  stacking_model: LogisticRegression # MLP, LogisticRegression

#bayesian_net:
#  algorithm: Tree  # HillClimb, PC, Tree, MMHC
#  prior_type: BDeu  # BDeu, K2, Dirichlet
#  use_cache: True
#  score_metric: bic  # bic, k2, bdeu, bds, aic.  The score to be optimized during structure estimation.
#  max_parents: 3 # 3, 5, 7
#  ci_test: 'pearsonr'  # For PC algorithm
#  significance_level: 0.05  # For PC algorithm
#  use_parents: True
#  verbose: False

bayesian_net:
  algorithm: HillClimb  # HillClimb, MMHC, PC, Tree
  score_metric: bic  # or k2, bdeu, bds
  prior_type: BDeu  # or K2
  use_parents: true
  max_parents: 3
  significance_level: 0.05  # for PC and MMHC
  ci_test: pearsonr  # for PC
  verbose: true
